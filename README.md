# LMstudio-Ollama-VSCode-Shim
FastAPI server that exposes an Ollama-compatible API and proxies requests to a running LM Studio instance on Mac.
